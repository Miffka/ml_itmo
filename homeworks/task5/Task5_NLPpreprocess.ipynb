{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import os\n",
    "import os.path as osp\n",
    "import re\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import spacy\n",
    "import tqdm\n",
    "\n",
    "from utils.config import config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'CHAPTER I.\\nDown the '"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fpath = osp.join(config.data_dir, \"task5\", \"alice.txt\")\n",
    "with open(fpath) as fin:\n",
    "    text = fin.read()\n",
    "text[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " I.\n",
      "Down the Ra\n",
      " II.\n",
      "The Pool o\n",
      " III.\n",
      "A Caucus-\n",
      " IV.\n",
      "The Rabbit\n",
      " V.\n",
      "Advice from\n",
      " VI.\n",
      "Pig and Pe\n",
      " VII.\n",
      "A Mad Tea\n",
      " VIII.\n",
      "The Quee\n",
      " IX.\n",
      "The Mock T\n",
      " X.\n",
      "The Lobster\n",
      " XI.\n",
      "Who Stole \n",
      " XII.\n",
      "Alice’s E\n"
     ]
    }
   ],
   "source": [
    "chapters = re.split(\"CHAPTER\", text)\n",
    "for chapter in chapters:\n",
    "    print(chapter[:15])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "doc = nlp(text.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chapter True False chapter NOUN\n",
      "i. False False i. NOUN\n",
      "\n",
      " False False \n",
      " SPACE\n",
      "down True True down ADP\n",
      "the True True the DET\n",
      "rabbit True False rabbit NOUN\n",
      "- False False - PUNCT\n",
      "hole True False hole NOUN\n",
      "\n",
      "\n",
      "\n",
      " False False \n",
      "\n",
      "\n",
      " SPACE\n",
      "alice True False alice NOUN\n"
     ]
    }
   ],
   "source": [
    "for token in doc[:10]:\n",
    "    print(token.text, token.is_alpha, token.is_stop, token.lemma_, token.pos_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Find 10 most important words in each chapter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13/13 [00:05<00:00,  2.33it/s]\n"
     ]
    }
   ],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "tokenized_chapters = []\n",
    "for chapter in tqdm.tqdm(chapters):\n",
    "    doc = nlp(chapter)\n",
    "    tokens = ' '.join([token.lemma_.lower() for token in doc if (token.is_alpha and not token.is_stop and not token.text == \"Alice\")])\n",
    "    tokenized_chapters.append(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "rabbit hol\n",
      "ii pool te\n",
      "iii caucus\n",
      "iv rabbit \n",
      "advice cat\n",
      "vi pig pep\n",
      "vii mad te\n",
      "viii queen\n",
      "ix mock tu\n",
      "lobster qu\n",
      "xi steal t\n",
      "xii eviden\n"
     ]
    }
   ],
   "source": [
    "for tokenized_chapter in tokenized_chapters:\n",
    "    print(tokenized_chapter[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12, 1761)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer()\n",
    "X = vectorizer.fit_transform(tokenized_chapters[1:])\n",
    "X = X.toarray()\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 ['fall' 'eat' 'think' 'little' 'bat' 'door' 'rabbit' 'key' 'go' 'way']\n",
      "2 ['mouse' 'pool' 'little' 'say' 'oh' 'swam' 'cat' 'think' 'dear' 'cry']\n",
      "3 ['say' 'mouse' 'dodo' 'prize' 'race' 'lory' 'dry' 'know' 'thimble' 'bird']\n",
      "4 ['bill' 'little' 'window' 'rabbit' 'puppy' 'grow' 'glove' 'fan' 'say'\n",
      " 'bottle']\n",
      "5 ['caterpillar' 'say' 'serpent' 'pigeon' 'youth' 'egg' 'size' 'think'\n",
      " 'father' 'little']\n",
      "6 ['say' 'footman' 'cat' 'baby' 'mad' 'duchess' 'grin' 'wow' 'think' 'go']\n",
      "7 ['hatter' 'dormouse' 'say' 'hare' 'march' 'tea' 'twinkle' 'time' 'know'\n",
      " 'go']\n",
      "8 ['queen' 'say' 'hedgehog' 'king' 'gardener' 'go' 'look' 'soldier' 'cat'\n",
      " 'procession']\n",
      "9 ['turtle' 'say' 'mock' 'gryphon' 'duchess' 'moral' 'queen' 'go' 'think'\n",
      " 'school']\n",
      "10 ['turtle' 'mock' 'gryphon' 'say' 'dance' 'lobster' 'soup' 'beautiful'\n",
      " 'whiting' 'soo']\n",
      "11 ['king' 'hatter' 'say' 'court' 'dormouse' 'witness' 'jury' 'queen'\n",
      " 'officer' 'juror']\n",
      "12 ['say' 'king' 'jury' 'dream' 'write' 'queen' 'sister' 'slate' 'rabbit'\n",
      " 'juryman']\n"
     ]
    }
   ],
   "source": [
    "feature_names = np.asarray(vectorizer.get_feature_names())\n",
    "for chapter_idx in range(X.shape[0]):\n",
    "    top_words = np.argsort(X[chapter_idx])[::-1][:10]\n",
    "    print(chapter_idx+1, feature_names[top_words])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's name chapters after 10 most important words:\n",
    "\n",
    "1. Little thinking during the fall\n",
    "2. Mouse says \"cat\" and cries\n",
    "3. Dry race with mouse and dodo\n",
    "4. Bill for rabbit's puppy\n",
    "5. Talk with caterpillar\n",
    "6. Dutchess mad with baby\n",
    "7. Tea with hatter and march hare\n",
    "8. Procession of the queen\n",
    "9. Moral talks with mock turtle and gryphon\n",
    "10. Lobster dance in soup\n",
    "11. King witness hatter in court\n",
    "12. The dream of queen's court"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Find the Top 10 most used verbs in sentences with Alice. What does Alice do most often?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('say', 174),\n",
       " ('think', 81),\n",
       " ('go', 47),\n",
       " ('look', 44),\n",
       " ('know', 36),\n",
       " ('begin', 34),\n",
       " ('come', 31),\n",
       " ('get', 26),\n",
       " ('feel', 25),\n",
       " ('find', 23)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "verbs = []\n",
    "\n",
    "for sent in doc.sents:\n",
    "    get_verbs = False\n",
    "    for token in sent:\n",
    "        if token.text.lower() == \"alice\":\n",
    "            get_verbs = True\n",
    "            break\n",
    "            \n",
    "    if get_verbs:\n",
    "        for token in sent:\n",
    "            if (token.pos_ == \"VERB\") and token.is_alpha and (not token.is_stop):\n",
    "                verbs.append(token.lemma_.lower())\n",
    "                \n",
    "counter = Counter(verbs)\n",
    "counter.most_common(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most of the time Alice says, thinks, knows, or feels something. Sometimes she acts - goes and comes anywhere, looks at something or finds something."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
